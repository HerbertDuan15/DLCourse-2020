{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SentimentClassification.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1dzWdur7z4yuHJpDgDLFEY_cyUrHGrBDQ","authorship_tag":"ABX9TyNHZeG2S+RWUIdbOtP2YHYp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"w8QZNC9bDmyG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593339101859,"user_tz":-480,"elapsed":5368,"user":{"displayName":"HJ D","photoUrl":"","userId":"11566204124165679378"}},"outputId":"68f3d7ba-deac-488e-d650-474652382335"},"source":["!pwd\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n","drive  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nmo1YfeMaS1Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593339115223,"user_tz":-480,"elapsed":1220,"user":{"displayName":"HJ D","photoUrl":"","userId":"11566204124165679378"}},"outputId":"05e6ba1b-0265-497c-d063-d69746bd0dfb"},"source":["cd ./drive/My Drive/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oNCXNvMLaXHb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593343920383,"user_tz":-480,"elapsed":579645,"user":{"displayName":"HJ D","photoUrl":"","userId":"11566204124165679378"}},"outputId":"ba0ccd19-fa70-477e-b9fc-eea09ecd3e88"},"source":["import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.utils.data as Data\n","import torchvision\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import gensim\n","#import gensim.models.word2vec as w2v\n","from sklearn.model_selection import train_test_split\n","import sklearn.metrics\n","import time\n","\n","\n","#数据预处理函数，返回文本与标签\n","def get_data(path):\n","#返回为文本，文本对应标签，文本数量\n","    data = []\n","    label = []\n","    nums = 0\n","    with open(path, 'r', encoding='UTF-8') as f:\n","        lines = f.readlines()\n","        text = ''\n","        for line in lines:\n","            try:\n","                label.append(torch.tensor(int(line[0]), dtype=torch.int64))\n","            except BaseException:  # 遇到首个字符不是标签的就跳过比如空行，并打印\n","                print('wrong line at:' + str(line) +  \",drop this line\")\n","                continue\n","            line_words = line.strip().split()[1:-1]  # 按照空字符\\t\\n 空格来切分\n","            text = line_words\n","            # print(text)\n","            data.append(text)\n","            nums = nums + 1\n","    return data, label, nums\n","#load word 2 vetc，加载词向量，可以事先预训练\n","def getw2v():\n","    model_file_name = 'wiki_word2vec_50.bin'\n","    # 模型训练，生成词向量\n","    '''\n","    sentences = w2v.LineSentence('trainword.txt')\n","    model = w2v.Word2Vec(sentences, size=20, window=5, min_count=5, workers=4)\n","    model.save(model_file_name)\n","    '''\n","    # model = w2v.Word2Vec.load(model_file_name)\n","    model = gensim.models.KeyedVectors.load_word2vec_format(model_file_name, binary=True)\n","    return model;\n","\n","train_texts,train_labels,train_nums=get_data('./train.txt') #texts[0:train_nums]\n","valid_texts,valid_labels,valid_nums=get_data('./validation.txt') #texts[train_nums:train_nums+valid_nums]\n","test_texts,test_labels,test_nums=get_data('./test.txt')#texts[train_nums+valid_nums:train_nums+valid_nums+test_nums]\n","texts = train_texts + valid_texts + test_texts\n","labels = train_labels + valid_labels + test_labels\n","\n","sentence_length = [len(x) for x in texts] #长度\n","%matplotlib inline\n","#notebook\n","import matplotlib.pyplot as plt\n","plt.hist(sentence_length,max(sentence_length))\n","plt.xlim(0,max(sentence_length)/2)\n","plt.show()\n","#句子长度设为100就足够了\n","\n","# time.sleep(100)\n","# print(texts[1])\n","# print(texts[-1])\n","# time.sleep(1000)\n","#textCNN模型\n","class textCNN(nn.Module):\n","    def __init__(self,args):\n","        super(textCNN, self).__init__()\n","        vocb_size = args['vocb_size']\n","        dim = args['dim']\n","        n_class = args['n_class']\n","        max_len = args['max_len']\n","        embedding_matrix=args['embedding_matrix']\n","        #需要将事先训练好的词向量载入\n","        self.embeding = nn.Embedding(vocb_size, dim,_weight=embedding_matrix)\n","        self.conv1 = nn.Sequential(\n","                     nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5,\n","                               stride=1, padding=2),\n","\n","                     nn.ReLU(),\n","                     nn.MaxPool2d(kernel_size=2) # (16,64,64)\n","                     )\n","        self.conv2 = nn.Sequential(\n","                     nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2),\n","                     nn.ReLU(),\n","                     nn.MaxPool2d(2)\n","                     )\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","        self.conv4 = nn.Sequential(  # (16,64,64)\n","            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, stride=1, padding=2),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2)\n","        )\n","        self.fc1 = nn.Linear(2304, 512)\n","        self.fc2 = nn.Linear(512, 100)\n","        self.out = nn.Linear(100, n_class)\n","\n","    def forward(self, x):\n","        x = self.embeding(x)\n","        x=x.view(x.size(0),1,max_len,word_dim)\n","        #print(x.size())\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        x = x.view(x.size(0), -1) # 将（batch，outchanel,w,h）展平为（batch，outchanel*w*h）\n","        # print(x.size())\n","        output = self.fc1(x)\n","        output = self.fc2(output)\n","        output = self.out(output)\n","        return output\n","\n","#此处统计了所有词的次数\n","word_vocb=[]\n","word_vocb.append('')\n","for text in texts:\n","    for word in text:\n","        word_vocb.append(word)\n","word_vocb=set(word_vocb)#使用set去重\n","vocb_size=len(word_vocb)#得到了出现的不同的词的个数 58463 个\n","# print(vocb_size) #58436\n","# time.sleep(1000)\n","#设置词表大小\n","nb_words=40000\n","if nb_words<vocb_size:\n","    nb_words=vocb_size\n","max_len=100;#限定的每个句子的长度，超过截取，小于补0\n","word_dim=50;#每个词vector的维度\n","n_class=2;#最后的分类\n","\n","\n","args={}\n","#textCNN调用的参数\n","args['vocb_size']=nb_words#词表大小\n","args['max_len']=max_len\n","args['n_class']=n_class\n","args['dim']=word_dim\n","\n","\n","#词表与索引的map\n","word_to_idx={word:i for i,word in enumerate(word_vocb)}\n","idx_to_word={word_to_idx[word]:word for word in word_to_idx}\n","#每个单词的对应的词向量\n","embeddings_index = getw2v()\n","#预先处理好的词向量\n","embedding_matrix = np.zeros((nb_words, word_dim))\n","for word, i in word_to_idx.items():\n","    if i >= nb_words:\n","        continue\n","    if word in embeddings_index:\n","        embedding_vector = embeddings_index[word]\n","        if embedding_vector is not None:\n","            # words not found in embedding index will be all-zeros.\n","            embedding_matrix[i] = embedding_vector\n","args['embedding_matrix']=torch.Tensor(embedding_matrix)\n","\n","#生成训练数据，需要将训练数据的Word转换为word的索引\n","texts_with_id=np.zeros([len(texts),max_len]) # 训练句子总数 * 句子长度的矩阵\n","for i in range(0,len(texts)):#第i句影评\n","    if len(texts[i])<max_len:#句子长度比max_len小\n","        for j in range(0,len(texts[i])):#其中第j个词\n","            texts_with_id[i][j]=word_to_idx[texts[i][j]]\n","        for j in range(len(texts[i]),max_len):\n","            texts_with_id[i][j] = word_to_idx['']\n","    else:\n","        for j in range(0,max_len):\n","            texts_with_id[i][j]=word_to_idx[texts[i][j]]\n","\n","#构建textCNN模型\n","cnn=textCNN(args)\n","print(cnn)\n","\n","EPOCH=3\n","LR = 0.001\n","optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n","#损失函数\n","loss_function = nn.CrossEntropyLoss()\n","#训练批次大小\n","batch_size=100;\n","#划分训练数据和测试数据\n","x_train, x_test, y_train, y_test = train_test_split(texts_with_id, labels, test_size=0.1, random_state = int(time.time()), shuffle = True)\n","\n","test_x=torch.LongTensor(x_test)\n","test_y=torch.LongTensor(y_test)\n","train_x=x_train\n","train_y=y_train\n","\n","test_batch_size=100;\n","#开始训练\n","for epoch in range(EPOCH):\n","    for i in range(0,(int)(len(train_x)/batch_size)):\n","        b_x = Variable(torch.LongTensor(train_x[i*batch_size:i*batch_size+batch_size]))\n","        b_y = Variable(torch.LongTensor((train_y[i*batch_size:i*batch_size+batch_size])))\n","        output = cnn(b_x)\n","        loss = loss_function(output, b_y)\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step() \n","        pred_y = torch.max(output, 1)[1].data.squeeze()\n","        # print(sklearn.metrics.accuracy_score(b_y.numpy().tolist(),pred_y.numpy().tolist()))\n","        acc = (b_y == pred_y)\n","        accuracy = acc.numpy().sum() / b_y.size(0)\n","        if(i+1)%10 == 0:\n","          print('TRAIN:EPOCH [%d/%d],batch[%d/%d],train loss is: %s, now accuracy is: %s\\n'%(epoch+1,EPOCH,i+1,len(train_x)/batch_size,str(loss.item()),str(accuracy)))\n","    \n","    # 测试\n","    test_all = 0\n","    test_right = 0\n","    pred = []\n","    target = []\n","    for j in range(0, (int)(len(test_x) / test_batch_size)):\n","        b_x = Variable(torch.LongTensor(test_x[j * test_batch_size:j * test_batch_size + test_batch_size]))\n","        b_y = Variable(torch.LongTensor((test_y[j * test_batch_size:j * test_batch_size + test_batch_size])))\n","        test_output = cnn(b_x)\n","        pred_y = torch.max(test_output, 1)[1].data.squeeze()\n","        pred += pred_y.numpy().tolist()\n","        target += b_y.numpy().tolist()\n","        acc = (pred_y == b_y)\n","        acc = acc.numpy().sum()\n","        now_acc = acc / b_y.size(0)\n","        test_right = test_right + acc\n","        test_all = test_all + b_y.size(0)\n","        total_acc = test_right / test_all\n","        print('TEST:in batch[%d/%d] accuracy is: %s, total accuracy is: %s\\n'%(j+1,len(test_x)/test_batch_size,str(now_acc),str(total_acc)))\n","        print(\"sklearn: now accuracy_score is %s,  precision_score is %s, recall_score is %s, f1-score is %s\"\n","        %(sklearn.metrics.accuracy_score(target,pred),sklearn.metrics.precision_score(target,pred,average='binary'),\n","          sklearn.metrics.recall_score(target,pred,average='binary'),sklearn.metrics.f1_score(target,pred,average='binary')  ))\n","        print(\"sklearn:confusion_matrix is \")\n","        print(sklearn.metrics.confusion_matrix(target,pred))\n","      \n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["wrong line at:\n",",drop this line\n","wrong line at:\n",",drop this line\n","wrong line at:\n",",drop this line\n","wrong line at:\n",",drop this line\n","wrong line at:\n",",drop this line\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"],"name":"stderr"},{"output_type":"stream","text":["textCNN(\n","  (embeding): Embedding(58463, 50)\n","  (conv1): Sequential(\n","    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv2): Sequential(\n","    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv3): Sequential(\n","    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (conv4): Sequential(\n","    (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (fc1): Linear(in_features=2304, out_features=512, bias=True)\n","  (fc2): Linear(in_features=512, out_features=100, bias=True)\n","  (out): Linear(in_features=100, out_features=2, bias=True)\n",")\n","TRAIN:EPOCH [1/3],batch[10/233],train loss is: 0.6948962211608887, now accuracy is: 0.47\n","\n","TRAIN:EPOCH [1/3],batch[20/233],train loss is: 0.6930304169654846, now accuracy is: 0.5\n","\n","TRAIN:EPOCH [1/3],batch[30/233],train loss is: 0.6922803521156311, now accuracy is: 0.52\n","\n","TRAIN:EPOCH [1/3],batch[40/233],train loss is: 0.6922006011009216, now accuracy is: 0.56\n","\n","TRAIN:EPOCH [1/3],batch[50/233],train loss is: 0.7282788753509521, now accuracy is: 0.37\n","\n","TRAIN:EPOCH [1/3],batch[60/233],train loss is: 0.6926977634429932, now accuracy is: 0.59\n","\n","TRAIN:EPOCH [1/3],batch[70/233],train loss is: 0.6928415894508362, now accuracy is: 0.48\n","\n","TRAIN:EPOCH [1/3],batch[80/233],train loss is: 0.6910428404808044, now accuracy is: 0.52\n","\n","TRAIN:EPOCH [1/3],batch[90/233],train loss is: 0.6928378343582153, now accuracy is: 0.49\n","\n","TRAIN:EPOCH [1/3],batch[100/233],train loss is: 0.6808927655220032, now accuracy is: 0.61\n","\n","TRAIN:EPOCH [1/3],batch[110/233],train loss is: 0.585204005241394, now accuracy is: 0.72\n","\n","TRAIN:EPOCH [1/3],batch[120/233],train loss is: 0.5369897484779358, now accuracy is: 0.77\n","\n","TRAIN:EPOCH [1/3],batch[130/233],train loss is: 0.5715939402580261, now accuracy is: 0.66\n","\n","TRAIN:EPOCH [1/3],batch[140/233],train loss is: 0.5070614814758301, now accuracy is: 0.75\n","\n","TRAIN:EPOCH [1/3],batch[150/233],train loss is: 0.47924134135246277, now accuracy is: 0.76\n","\n","TRAIN:EPOCH [1/3],batch[160/233],train loss is: 0.4250955879688263, now accuracy is: 0.8\n","\n","TRAIN:EPOCH [1/3],batch[170/233],train loss is: 0.5060029029846191, now accuracy is: 0.71\n","\n","TRAIN:EPOCH [1/3],batch[180/233],train loss is: 0.48588451743125916, now accuracy is: 0.74\n","\n","TRAIN:EPOCH [1/3],batch[190/233],train loss is: 0.5347873568534851, now accuracy is: 0.8\n","\n","TRAIN:EPOCH [1/3],batch[200/233],train loss is: 0.5999442934989929, now accuracy is: 0.7\n","\n","TRAIN:EPOCH [1/3],batch[210/233],train loss is: 0.39578694105148315, now accuracy is: 0.83\n","\n","TRAIN:EPOCH [1/3],batch[220/233],train loss is: 0.5404678583145142, now accuracy is: 0.71\n","\n","TRAIN:EPOCH [1/3],batch[230/233],train loss is: 0.4119724929332733, now accuracy is: 0.78\n","\n","TEST:in batch[1/26] accuracy is: 0.75, total accuracy is: 0.75\n","\n","sklearn: now accuracy_score is 0.75,  precision_score is 0.8809523809523809, recall_score is 0.6491228070175439, f1-score is 0.7474747474747475\n","sklearn:confusion_matrix is \n","[[38  5]\n"," [20 37]]\n","TEST:in batch[2/26] accuracy is: 0.74, total accuracy is: 0.745\n","\n","sklearn: now accuracy_score is 0.745,  precision_score is 0.8080808080808081, recall_score is 0.7142857142857143, f1-score is 0.7582938388625592\n","sklearn:confusion_matrix is \n","[[69 19]\n"," [32 80]]\n","TEST:in batch[3/26] accuracy is: 0.82, total accuracy is: 0.77\n","\n","sklearn: now accuracy_score is 0.77,  precision_score is 0.8148148148148148, recall_score is 0.7142857142857143, f1-score is 0.7612456747404844\n","sklearn:confusion_matrix is \n","[[121  25]\n"," [ 44 110]]\n","TEST:in batch[4/26] accuracy is: 0.9, total accuracy is: 0.8025\n","\n","sklearn: now accuracy_score is 0.8025,  precision_score is 0.8457446808510638, recall_score is 0.7607655502392344, f1-score is 0.801007556675063\n","sklearn:confusion_matrix is \n","[[162  29]\n"," [ 50 159]]\n","TEST:in batch[5/26] accuracy is: 0.8, total accuracy is: 0.802\n","\n","sklearn: now accuracy_score is 0.802,  precision_score is 0.8291666666666667, recall_score is 0.77431906614786, f1-score is 0.8008048289738431\n","sklearn:confusion_matrix is \n","[[202  41]\n"," [ 58 199]]\n","TEST:in batch[6/26] accuracy is: 0.84, total accuracy is: 0.8083333333333333\n","\n","sklearn: now accuracy_score is 0.8083333333333333,  precision_score is 0.8363636363636363, recall_score is 0.7666666666666667, f1-score is 0.8\n","sklearn:confusion_matrix is \n","[[255  45]\n"," [ 70 230]]\n","TEST:in batch[7/26] accuracy is: 0.89, total accuracy is: 0.82\n","\n","sklearn: now accuracy_score is 0.82,  precision_score is 0.8522012578616353, recall_score is 0.7742857142857142, f1-score is 0.8113772455089819\n","sklearn:confusion_matrix is \n","[[303  47]\n"," [ 79 271]]\n","TEST:in batch[8/26] accuracy is: 0.74, total accuracy is: 0.81\n","\n","sklearn: now accuracy_score is 0.81,  precision_score is 0.8351648351648352, recall_score is 0.7676767676767676, f1-score is 0.8\n","sklearn:confusion_matrix is \n","[[344  60]\n"," [ 92 304]]\n","TEST:in batch[9/26] accuracy is: 0.75, total accuracy is: 0.8033333333333333\n","\n","sklearn: now accuracy_score is 0.8033333333333333,  precision_score is 0.8265060240963855, recall_score is 0.765625, f1-score is 0.7949015063731171\n","sklearn:confusion_matrix is \n","[[380  72]\n"," [105 343]]\n","TEST:in batch[10/26] accuracy is: 0.72, total accuracy is: 0.795\n","\n","sklearn: now accuracy_score is 0.795,  precision_score is 0.8043010752688172, recall_score is 0.7663934426229508, f1-score is 0.7848898216159496\n","sklearn:confusion_matrix is \n","[[421  91]\n"," [114 374]]\n","TEST:in batch[11/26] accuracy is: 0.77, total accuracy is: 0.7927272727272727\n","\n","sklearn: now accuracy_score is 0.7927272727272727,  precision_score is 0.8, recall_score is 0.7672253258845437, f1-score is 0.7832699619771862\n","sklearn:confusion_matrix is \n","[[460 103]\n"," [125 412]]\n","TEST:in batch[12/26] accuracy is: 0.83, total accuracy is: 0.7958333333333333\n","\n","sklearn: now accuracy_score is 0.7958333333333333,  precision_score is 0.8099467140319716, recall_score is 0.7676767676767676, f1-score is 0.7882454624027657\n","sklearn:confusion_matrix is \n","[[499 107]\n"," [138 456]]\n","TEST:in batch[13/26] accuracy is: 0.67, total accuracy is: 0.7861538461538462\n","\n","sklearn: now accuracy_score is 0.7861538461538462,  precision_score is 0.7986906710310966, recall_score is 0.7589424572317263, f1-score is 0.7783094098883572\n","sklearn:confusion_matrix is \n","[[534 123]\n"," [155 488]]\n","TEST:in batch[14/26] accuracy is: 0.8, total accuracy is: 0.7871428571428571\n","\n","sklearn: now accuracy_score is 0.7871428571428571,  precision_score is 0.7981790591805766, recall_score is 0.7612156295224313, f1-score is 0.7792592592592592\n","sklearn:confusion_matrix is \n","[[576 133]\n"," [165 526]]\n","TEST:in batch[15/26] accuracy is: 0.86, total accuracy is: 0.792\n","\n","sklearn: now accuracy_score is 0.792,  precision_score is 0.8016997167138811, recall_score is 0.7669376693766937, f1-score is 0.7839335180055401\n","sklearn:confusion_matrix is \n","[[622 140]\n"," [172 566]]\n","TEST:in batch[16/26] accuracy is: 0.81, total accuracy is: 0.793125\n","\n","sklearn: now accuracy_score is 0.793125,  precision_score is 0.8042328042328042, recall_score is 0.7686472819216182, f1-score is 0.7860374919198448\n","sklearn:confusion_matrix is \n","[[661 148]\n"," [183 608]]\n","TEST:in batch[17/26] accuracy is: 0.83, total accuracy is: 0.7952941176470588\n","\n","sklearn: now accuracy_score is 0.7952941176470588,  precision_score is 0.8079306071871127, recall_score is 0.7715976331360946, f1-score is 0.7893462469733656\n","sklearn:confusion_matrix is \n","[[700 155]\n"," [193 652]]\n","TEST:in batch[18/26] accuracy is: 0.81, total accuracy is: 0.7961111111111111\n","\n","sklearn: now accuracy_score is 0.7961111111111111,  precision_score is 0.806674338319908, recall_score is 0.7788888888888889, f1-score is 0.7925381571509329\n","sklearn:confusion_matrix is \n","[[732 168]\n"," [199 701]]\n","TEST:in batch[19/26] accuracy is: 0.84, total accuracy is: 0.7984210526315789\n","\n","sklearn: now accuracy_score is 0.7984210526315789,  precision_score is 0.8089519650655022, recall_score is 0.7808219178082192, f1-score is 0.7946380697050939\n","sklearn:confusion_matrix is \n","[[776 175]\n"," [208 741]]\n","TEST:in batch[20/26] accuracy is: 0.82, total accuracy is: 0.7995\n","\n","sklearn: now accuracy_score is 0.7995,  precision_score is 0.8077324973876698, recall_score is 0.7808080808080808, f1-score is 0.7940421160760145\n","sklearn:confusion_matrix is \n","[[826 184]\n"," [217 773]]\n","TEST:in batch[21/26] accuracy is: 0.79, total accuracy is: 0.799047619047619\n","\n","sklearn: now accuracy_score is 0.799047619047619,  precision_score is 0.810379241516966, recall_score is 0.7777777777777778, f1-score is 0.7937438905180841\n","sklearn:confusion_matrix is \n","[[866 190]\n"," [232 812]]\n","TEST:in batch[22/26] accuracy is: 0.8, total accuracy is: 0.7990909090909091\n","\n","sklearn: now accuracy_score is 0.7990909090909091,  precision_score is 0.8110687022900763, recall_score is 0.7769652650822669, f1-score is 0.7936507936507936\n","sklearn:confusion_matrix is \n","[[908 198]\n"," [244 850]]\n","TEST:in batch[23/26] accuracy is: 0.85, total accuracy is: 0.801304347826087\n","\n","sklearn: now accuracy_score is 0.801304347826087,  precision_score is 0.8146118721461187, recall_score is 0.7783595113438045, f1-score is 0.7960731816153503\n","sklearn:confusion_matrix is \n","[[951 203]\n"," [254 892]]\n","TEST:in batch[24/26] accuracy is: 0.84, total accuracy is: 0.8029166666666666\n","\n","sklearn: now accuracy_score is 0.8029166666666666,  precision_score is 0.8150087260034904, recall_score is 0.7815899581589958, f1-score is 0.7979495941905168\n","sklearn:confusion_matrix is \n","[[993 212]\n"," [261 934]]\n","TEST:in batch[25/26] accuracy is: 0.81, total accuracy is: 0.8032\n","\n","sklearn: now accuracy_score is 0.8032,  precision_score is 0.8149078726968174, recall_score is 0.7821543408360129, f1-score is 0.7981952420016407\n","sklearn:confusion_matrix is \n","[[1035  221]\n"," [ 271  973]]\n","TEST:in batch[26/26] accuracy is: 0.85, total accuracy is: 0.805\n","\n","sklearn: now accuracy_score is 0.805,  precision_score is 0.8198707592891761, recall_score is 0.7813702848344881, f1-score is 0.800157666535278\n","sklearn:confusion_matrix is \n","[[1078  223]\n"," [ 284 1015]]\n","TRAIN:EPOCH [2/3],batch[10/233],train loss is: 0.3719363510608673, now accuracy is: 0.82\n","\n","TRAIN:EPOCH [2/3],batch[20/233],train loss is: 0.5044196844100952, now accuracy is: 0.78\n","\n","TRAIN:EPOCH [2/3],batch[30/233],train loss is: 0.4509202539920807, now accuracy is: 0.8\n","\n","TRAIN:EPOCH [2/3],batch[40/233],train loss is: 0.48131299018859863, now accuracy is: 0.75\n","\n","TRAIN:EPOCH [2/3],batch[50/233],train loss is: 0.4155968129634857, now accuracy is: 0.81\n","\n","TRAIN:EPOCH [2/3],batch[60/233],train loss is: 0.3869614899158478, now accuracy is: 0.82\n","\n","TRAIN:EPOCH [2/3],batch[70/233],train loss is: 0.330369234085083, now accuracy is: 0.86\n","\n","TRAIN:EPOCH [2/3],batch[80/233],train loss is: 0.369222491979599, now accuracy is: 0.83\n","\n","TRAIN:EPOCH [2/3],batch[90/233],train loss is: 0.3308030068874359, now accuracy is: 0.85\n","\n","TRAIN:EPOCH [2/3],batch[100/233],train loss is: 0.38549667596817017, now accuracy is: 0.84\n","\n","TRAIN:EPOCH [2/3],batch[110/233],train loss is: 0.34816116094589233, now accuracy is: 0.83\n","\n","TRAIN:EPOCH [2/3],batch[120/233],train loss is: 0.26731133460998535, now accuracy is: 0.89\n","\n","TRAIN:EPOCH [2/3],batch[130/233],train loss is: 0.3340516686439514, now accuracy is: 0.87\n","\n","TRAIN:EPOCH [2/3],batch[140/233],train loss is: 0.2781293988227844, now accuracy is: 0.85\n","\n","TRAIN:EPOCH [2/3],batch[150/233],train loss is: 0.34570589661598206, now accuracy is: 0.83\n","\n","TRAIN:EPOCH [2/3],batch[160/233],train loss is: 0.21743665635585785, now accuracy is: 0.9\n","\n","TRAIN:EPOCH [2/3],batch[170/233],train loss is: 0.3121400773525238, now accuracy is: 0.89\n","\n","TRAIN:EPOCH [2/3],batch[180/233],train loss is: 0.37155863642692566, now accuracy is: 0.81\n","\n","TRAIN:EPOCH [2/3],batch[190/233],train loss is: 0.39940768480300903, now accuracy is: 0.91\n","\n","TRAIN:EPOCH [2/3],batch[200/233],train loss is: 0.33600354194641113, now accuracy is: 0.82\n","\n","TRAIN:EPOCH [2/3],batch[210/233],train loss is: 0.20746544003486633, now accuracy is: 0.9\n","\n","TRAIN:EPOCH [2/3],batch[220/233],train loss is: 0.4022514820098877, now accuracy is: 0.81\n","\n","TRAIN:EPOCH [2/3],batch[230/233],train loss is: 0.22937338054180145, now accuracy is: 0.9\n","\n","TEST:in batch[1/26] accuracy is: 0.81, total accuracy is: 0.81\n","\n","sklearn: now accuracy_score is 0.81,  precision_score is 0.88, recall_score is 0.7719298245614035, f1-score is 0.822429906542056\n","sklearn:confusion_matrix is \n","[[37  6]\n"," [13 44]]\n","TEST:in batch[2/26] accuracy is: 0.81, total accuracy is: 0.81\n","\n","sklearn: now accuracy_score is 0.81,  precision_score is 0.8557692307692307, recall_score is 0.7946428571428571, f1-score is 0.824074074074074\n","sklearn:confusion_matrix is \n","[[73 15]\n"," [23 89]]\n","TEST:in batch[3/26] accuracy is: 0.86, total accuracy is: 0.8266666666666667\n","\n","sklearn: now accuracy_score is 0.8266666666666667,  precision_score is 0.8591549295774648, recall_score is 0.7922077922077922, f1-score is 0.8243243243243243\n","sklearn:confusion_matrix is \n","[[126  20]\n"," [ 32 122]]\n","TEST:in batch[4/26] accuracy is: 0.94, total accuracy is: 0.855\n","\n","sklearn: now accuracy_score is 0.855,  precision_score is 0.8793969849246231, recall_score is 0.8373205741626795, f1-score is 0.8578431372549019\n","sklearn:confusion_matrix is \n","[[167  24]\n"," [ 34 175]]\n","TEST:in batch[5/26] accuracy is: 0.85, total accuracy is: 0.854\n","\n","sklearn: now accuracy_score is 0.854,  precision_score is 0.8650793650793651, recall_score is 0.8482490272373541, f1-score is 0.8565815324165029\n","sklearn:confusion_matrix is \n","[[209  34]\n"," [ 39 218]]\n","TEST:in batch[6/26] accuracy is: 0.88, total accuracy is: 0.8583333333333333\n","\n","sklearn: now accuracy_score is 0.8583333333333333,  precision_score is 0.8668941979522184, recall_score is 0.8466666666666667, f1-score is 0.8566610455311974\n","sklearn:confusion_matrix is \n","[[261  39]\n"," [ 46 254]]\n","TEST:in batch[7/26] accuracy is: 0.87, total accuracy is: 0.86\n","\n","sklearn: now accuracy_score is 0.86,  precision_score is 0.8705882352941177, recall_score is 0.8457142857142858, f1-score is 0.8579710144927537\n","sklearn:confusion_matrix is \n","[[306  44]\n"," [ 54 296]]\n","TEST:in batch[8/26] accuracy is: 0.74, total accuracy is: 0.845\n","\n","sklearn: now accuracy_score is 0.845,  precision_score is 0.8523316062176166, recall_score is 0.8308080808080808, f1-score is 0.8414322250639387\n","sklearn:confusion_matrix is \n","[[347  57]\n"," [ 67 329]]\n","TEST:in batch[9/26] accuracy is: 0.81, total accuracy is: 0.8411111111111111\n","\n","sklearn: now accuracy_score is 0.8411111111111111,  precision_score is 0.8473804100227791, recall_score is 0.8303571428571429, f1-score is 0.8387824126268322\n","sklearn:confusion_matrix is \n","[[385  67]\n"," [ 76 372]]\n","TEST:in batch[10/26] accuracy is: 0.76, total accuracy is: 0.833\n","\n","sklearn: now accuracy_score is 0.833,  precision_score is 0.8282208588957055, recall_score is 0.8299180327868853, f1-score is 0.8290685772773798\n","sklearn:confusion_matrix is \n","[[428  84]\n"," [ 83 405]]\n","TEST:in batch[11/26] accuracy is: 0.77, total accuracy is: 0.8272727272727273\n","\n","sklearn: now accuracy_score is 0.8272727272727273,  precision_score is 0.8195211786372008, recall_score is 0.8286778398510242, f1-score is 0.8240740740740741\n","sklearn:confusion_matrix is \n","[[465  98]\n"," [ 92 445]]\n","TEST:in batch[12/26] accuracy is: 0.9, total accuracy is: 0.8333333333333334\n","\n","sklearn: now accuracy_score is 0.8333333333333334,  precision_score is 0.8338983050847457, recall_score is 0.8282828282828283, f1-score is 0.8310810810810811\n","sklearn:confusion_matrix is \n","[[508  98]\n"," [102 492]]\n","TEST:in batch[13/26] accuracy is: 0.7, total accuracy is: 0.823076923076923\n","\n","sklearn: now accuracy_score is 0.823076923076923,  precision_score is 0.8211508553654744, recall_score is 0.8211508553654744, f1-score is 0.8211508553654744\n","sklearn:confusion_matrix is \n","[[542 115]\n"," [115 528]]\n","TEST:in batch[14/26] accuracy is: 0.84, total accuracy is: 0.8242857142857143\n","\n","sklearn: now accuracy_score is 0.8242857142857143,  precision_score is 0.8219971056439942, recall_score is 0.8219971056439942, f1-score is 0.8219971056439943\n","sklearn:confusion_matrix is \n","[[586 123]\n"," [123 568]]\n","TEST:in batch[15/26] accuracy is: 0.85, total accuracy is: 0.826\n","\n","sklearn: now accuracy_score is 0.826,  precision_score is 0.8218623481781376, recall_score is 0.8252032520325203, f1-score is 0.8235294117647057\n","sklearn:confusion_matrix is \n","[[630 132]\n"," [129 609]]\n","TEST:in batch[16/26] accuracy is: 0.83, total accuracy is: 0.82625\n","\n","sklearn: now accuracy_score is 0.82625,  precision_score is 0.8242730720606827, recall_score is 0.8242730720606827, f1-score is 0.8242730720606826\n","sklearn:confusion_matrix is \n","[[670 139]\n"," [139 652]]\n","TEST:in batch[17/26] accuracy is: 0.85, total accuracy is: 0.8276470588235294\n","\n","sklearn: now accuracy_score is 0.8276470588235294,  precision_score is 0.827790973871734, recall_score is 0.8248520710059172, f1-score is 0.8263189093064611\n","sklearn:confusion_matrix is \n","[[710 145]\n"," [148 697]]\n","TEST:in batch[18/26] accuracy is: 0.83, total accuracy is: 0.8277777777777777\n","\n","sklearn: now accuracy_score is 0.8277777777777777,  precision_score is 0.82560706401766, recall_score is 0.8311111111111111, f1-score is 0.8283499446290145\n","sklearn:confusion_matrix is \n","[[742 158]\n"," [152 748]]\n","TEST:in batch[19/26] accuracy is: 0.87, total accuracy is: 0.83\n","\n","sklearn: now accuracy_score is 0.83,  precision_score is 0.826722338204593, recall_score is 0.8345626975763962, f1-score is 0.8306240167802832\n","sklearn:confusion_matrix is \n","[[785 166]\n"," [157 792]]\n","TEST:in batch[20/26] accuracy is: 0.83, total accuracy is: 0.83\n","\n","sklearn: now accuracy_score is 0.83,  precision_score is 0.8237051792828686, recall_score is 0.8353535353535354, f1-score is 0.8294884653961886\n","sklearn:confusion_matrix is \n","[[833 177]\n"," [163 827]]\n","TEST:in batch[21/26] accuracy is: 0.85, total accuracy is: 0.830952380952381\n","\n","sklearn: now accuracy_score is 0.830952380952381,  precision_score is 0.8271604938271605, recall_score is 0.8342911877394636, f1-score is 0.8307105388650454\n","sklearn:confusion_matrix is \n","[[874 182]\n"," [173 871]]\n","TEST:in batch[22/26] accuracy is: 0.78, total accuracy is: 0.8286363636363636\n","\n","sklearn: now accuracy_score is 0.8286363636363636,  precision_score is 0.8250226654578422, recall_score is 0.8318098720292505, f1-score is 0.8284023668639053\n","sklearn:confusion_matrix is \n","[[913 193]\n"," [184 910]]\n","TEST:in batch[23/26] accuracy is: 0.87, total accuracy is: 0.8304347826086956\n","\n","sklearn: now accuracy_score is 0.8304347826086956,  precision_score is 0.828125, recall_score is 0.8324607329842932, f1-score is 0.8302872062663185\n","sklearn:confusion_matrix is \n","[[956 198]\n"," [192 954]]\n","TEST:in batch[24/26] accuracy is: 0.84, total accuracy is: 0.8308333333333333\n","\n","sklearn: now accuracy_score is 0.8308333333333333,  precision_score is 0.827930174563591, recall_score is 0.8334728033472804, f1-score is 0.8306922435362804\n","sklearn:confusion_matrix is \n","[[998 207]\n"," [199 996]]\n","TEST:in batch[25/26] accuracy is: 0.87, total accuracy is: 0.8324\n","\n","sklearn: now accuracy_score is 0.8324,  precision_score is 0.829736211031175, recall_score is 0.8344051446945338, f1-score is 0.832064128256513\n","sklearn:confusion_matrix is \n","[[1043  213]\n"," [ 206 1038]]\n","TEST:in batch[26/26] accuracy is: 0.88, total accuracy is: 0.8342307692307692\n","\n","sklearn: now accuracy_score is 0.8342307692307692,  precision_score is 0.8348765432098766, recall_score is 0.8329484218629715, f1-score is 0.8339113680154142\n","sklearn:confusion_matrix is \n","[[1087  214]\n"," [ 217 1082]]\n","TRAIN:EPOCH [3/3],batch[10/233],train loss is: 0.20501531660556793, now accuracy is: 0.91\n","\n","TRAIN:EPOCH [3/3],batch[20/233],train loss is: 0.3179279863834381, now accuracy is: 0.85\n","\n","TRAIN:EPOCH [3/3],batch[30/233],train loss is: 0.29999348521232605, now accuracy is: 0.9\n","\n","TRAIN:EPOCH [3/3],batch[40/233],train loss is: 0.3452868163585663, now accuracy is: 0.87\n","\n","TRAIN:EPOCH [3/3],batch[50/233],train loss is: 0.24897454679012299, now accuracy is: 0.9\n","\n","TRAIN:EPOCH [3/3],batch[60/233],train loss is: 0.24492624402046204, now accuracy is: 0.89\n","\n","TRAIN:EPOCH [3/3],batch[70/233],train loss is: 0.24794723093509674, now accuracy is: 0.9\n","\n","TRAIN:EPOCH [3/3],batch[80/233],train loss is: 0.25413671135902405, now accuracy is: 0.91\n","\n","TRAIN:EPOCH [3/3],batch[90/233],train loss is: 0.17712867259979248, now accuracy is: 0.93\n","\n","TRAIN:EPOCH [3/3],batch[100/233],train loss is: 0.28222665190696716, now accuracy is: 0.89\n","\n","TRAIN:EPOCH [3/3],batch[110/233],train loss is: 0.27068865299224854, now accuracy is: 0.88\n","\n","TRAIN:EPOCH [3/3],batch[120/233],train loss is: 0.14530536532402039, now accuracy is: 0.96\n","\n","TRAIN:EPOCH [3/3],batch[130/233],train loss is: 0.15286098420619965, now accuracy is: 0.94\n","\n","TRAIN:EPOCH [3/3],batch[140/233],train loss is: 0.12103505432605743, now accuracy is: 0.96\n","\n","TRAIN:EPOCH [3/3],batch[150/233],train loss is: 0.18422646820545197, now accuracy is: 0.92\n","\n","TRAIN:EPOCH [3/3],batch[160/233],train loss is: 0.10957193374633789, now accuracy is: 0.97\n","\n","TRAIN:EPOCH [3/3],batch[170/233],train loss is: 0.22597858309745789, now accuracy is: 0.94\n","\n","TRAIN:EPOCH [3/3],batch[180/233],train loss is: 0.24709127843379974, now accuracy is: 0.9\n","\n","TRAIN:EPOCH [3/3],batch[190/233],train loss is: 0.2980312407016754, now accuracy is: 0.93\n","\n","TRAIN:EPOCH [3/3],batch[200/233],train loss is: 0.14013820886611938, now accuracy is: 0.96\n","\n","TRAIN:EPOCH [3/3],batch[210/233],train loss is: 0.07709714770317078, now accuracy is: 0.99\n","\n","TRAIN:EPOCH [3/3],batch[220/233],train loss is: 0.24300634860992432, now accuracy is: 0.91\n","\n","TRAIN:EPOCH [3/3],batch[230/233],train loss is: 0.07936462759971619, now accuracy is: 0.99\n","\n","TEST:in batch[1/26] accuracy is: 0.82, total accuracy is: 0.82\n","\n","sklearn: now accuracy_score is 0.82,  precision_score is 0.8823529411764706, recall_score is 0.7894736842105263, f1-score is 0.8333333333333333\n","sklearn:confusion_matrix is \n","[[37  6]\n"," [12 45]]\n","TEST:in batch[2/26] accuracy is: 0.8, total accuracy is: 0.81\n","\n","sklearn: now accuracy_score is 0.81,  precision_score is 0.8557692307692307, recall_score is 0.7946428571428571, f1-score is 0.824074074074074\n","sklearn:confusion_matrix is \n","[[73 15]\n"," [23 89]]\n","TEST:in batch[3/26] accuracy is: 0.88, total accuracy is: 0.8333333333333334\n","\n","sklearn: now accuracy_score is 0.8333333333333334,  precision_score is 0.8611111111111112, recall_score is 0.8051948051948052, f1-score is 0.8322147651006712\n","sklearn:confusion_matrix is \n","[[126  20]\n"," [ 30 124]]\n","TEST:in batch[4/26] accuracy is: 0.93, total accuracy is: 0.8575\n","\n","sklearn: now accuracy_score is 0.8575,  precision_score is 0.8877551020408163, recall_score is 0.8325358851674641, f1-score is 0.8592592592592594\n","sklearn:confusion_matrix is \n","[[169  22]\n"," [ 35 174]]\n","TEST:in batch[5/26] accuracy is: 0.87, total accuracy is: 0.86\n","\n","sklearn: now accuracy_score is 0.86,  precision_score is 0.8785425101214575, recall_score is 0.8443579766536965, f1-score is 0.861111111111111\n","sklearn:confusion_matrix is \n","[[213  30]\n"," [ 40 217]]\n","TEST:in batch[6/26] accuracy is: 0.86, total accuracy is: 0.86\n","\n","sklearn: now accuracy_score is 0.86,  precision_score is 0.8724137931034482, recall_score is 0.8433333333333334, f1-score is 0.8576271186440678\n","sklearn:confusion_matrix is \n","[[263  37]\n"," [ 47 253]]\n","TEST:in batch[7/26] accuracy is: 0.89, total accuracy is: 0.8642857142857143\n","\n","sklearn: now accuracy_score is 0.8642857142857143,  precision_score is 0.8761061946902655, recall_score is 0.8485714285714285, f1-score is 0.8621190130624092\n","sklearn:confusion_matrix is \n","[[308  42]\n"," [ 53 297]]\n","TEST:in batch[8/26] accuracy is: 0.78, total accuracy is: 0.85375\n","\n","sklearn: now accuracy_score is 0.85375,  precision_score is 0.8604651162790697, recall_score is 0.8409090909090909, f1-score is 0.8505747126436781\n","sklearn:confusion_matrix is \n","[[350  54]\n"," [ 63 333]]\n","TEST:in batch[9/26] accuracy is: 0.84, total accuracy is: 0.8522222222222222\n","\n","sklearn: now accuracy_score is 0.8522222222222222,  precision_score is 0.8604118993135011, recall_score is 0.8392857142857143, f1-score is 0.8497175141242939\n","sklearn:confusion_matrix is \n","[[391  61]\n"," [ 72 376]]\n","TEST:in batch[10/26] accuracy is: 0.72, total accuracy is: 0.839\n","\n","sklearn: now accuracy_score is 0.839,  precision_score is 0.8371134020618557, recall_score is 0.8319672131147541, f1-score is 0.8345323741007193\n","sklearn:confusion_matrix is \n","[[433  79]\n"," [ 82 406]]\n","TEST:in batch[11/26] accuracy is: 0.83, total accuracy is: 0.8381818181818181\n","\n","sklearn: now accuracy_score is 0.8381818181818181,  precision_score is 0.8367729831144465, recall_score is 0.8305400372439479, f1-score is 0.8336448598130841\n","sklearn:confusion_matrix is \n","[[476  87]\n"," [ 91 446]]\n","TEST:in batch[12/26] accuracy is: 0.87, total accuracy is: 0.8408333333333333\n","\n","sklearn: now accuracy_score is 0.8408333333333333,  precision_score is 0.8480138169257341, recall_score is 0.8265993265993266, f1-score is 0.8371696504688833\n","sklearn:confusion_matrix is \n","[[518  88]\n"," [103 491]]\n","TEST:in batch[13/26] accuracy is: 0.73, total accuracy is: 0.8323076923076923\n","\n","sklearn: now accuracy_score is 0.8323076923076923,  precision_score is 0.8378378378378378, recall_score is 0.8195956454121306, f1-score is 0.8286163522012578\n","sklearn:confusion_matrix is \n","[[555 102]\n"," [116 527]]\n","TEST:in batch[14/26] accuracy is: 0.79, total accuracy is: 0.8292857142857143\n","\n","sklearn: now accuracy_score is 0.8292857142857143,  precision_score is 0.834319526627219, recall_score is 0.8162083936324168, f1-score is 0.825164594001463\n","sklearn:confusion_matrix is \n","[[597 112]\n"," [127 564]]\n","TEST:in batch[15/26] accuracy is: 0.87, total accuracy is: 0.832\n","\n","sklearn: now accuracy_score is 0.832,  precision_score is 0.835635359116022, recall_score is 0.8197831978319783, f1-score is 0.8276333789329685\n","sklearn:confusion_matrix is \n","[[643 119]\n"," [133 605]]\n","TEST:in batch[16/26] accuracy is: 0.81, total accuracy is: 0.830625\n","\n","sklearn: now accuracy_score is 0.830625,  precision_score is 0.8350515463917526, recall_score is 0.8192161820480405, f1-score is 0.8270580727504786\n","sklearn:confusion_matrix is \n","[[681 128]\n"," [143 648]]\n","TEST:in batch[17/26] accuracy is: 0.86, total accuracy is: 0.8323529411764706\n","\n","sklearn: now accuracy_score is 0.8323529411764706,  precision_score is 0.8381642512077294, recall_score is 0.821301775147929, f1-score is 0.8296473401075911\n","sklearn:confusion_matrix is \n","[[721 134]\n"," [151 694]]\n","TEST:in batch[18/26] accuracy is: 0.81, total accuracy is: 0.8311111111111111\n","\n","sklearn: now accuracy_score is 0.8311111111111111,  precision_score is 0.8348314606741573, recall_score is 0.8255555555555556, f1-score is 0.8301675977653632\n","sklearn:confusion_matrix is \n","[[753 147]\n"," [157 743]]\n","TEST:in batch[19/26] accuracy is: 0.86, total accuracy is: 0.8326315789473684\n","\n","sklearn: now accuracy_score is 0.8326315789473684,  precision_score is 0.8359957401490948, recall_score is 0.827186512118019, f1-score is 0.8315677966101696\n","sklearn:confusion_matrix is \n","[[797 154]\n"," [164 785]]\n","TEST:in batch[20/26] accuracy is: 0.85, total accuracy is: 0.8335\n","\n","sklearn: now accuracy_score is 0.8335,  precision_score is 0.8341810783316378, recall_score is 0.8282828282828283, f1-score is 0.8312214901165738\n","sklearn:confusion_matrix is \n","[[847 163]\n"," [170 820]]\n","TEST:in batch[21/26] accuracy is: 0.86, total accuracy is: 0.8347619047619048\n","\n","sklearn: now accuracy_score is 0.8347619047619048,  precision_score is 0.8380213385063046, recall_score is 0.8275862068965517, f1-score is 0.8327710843373494\n","sklearn:confusion_matrix is \n","[[889 167]\n"," [180 864]]\n","TEST:in batch[22/26] accuracy is: 0.75, total accuracy is: 0.8309090909090909\n","\n","sklearn: now accuracy_score is 0.8309090909090909,  precision_score is 0.8342592592592593, recall_score is 0.823583180987203, f1-score is 0.8288868445262191\n","sklearn:confusion_matrix is \n","[[927 179]\n"," [193 901]]\n","TEST:in batch[23/26] accuracy is: 0.88, total accuracy is: 0.8330434782608696\n","\n","sklearn: now accuracy_score is 0.8330434782608696,  precision_score is 0.8377659574468085, recall_score is 0.824607329842932, f1-score is 0.8311345646437994\n","sklearn:confusion_matrix is \n","[[971 183]\n"," [201 945]]\n","TEST:in batch[24/26] accuracy is: 0.81, total accuracy is: 0.8320833333333333\n","\n","sklearn: now accuracy_score is 0.8320833333333333,  precision_score is 0.8367346938775511, recall_score is 0.8234309623430962, f1-score is 0.8300295234078447\n","sklearn:confusion_matrix is \n","[[1013  192]\n"," [ 211  984]]\n","TEST:in batch[25/26] accuracy is: 0.92, total accuracy is: 0.8356\n","\n","sklearn: now accuracy_score is 0.8356,  precision_score is 0.84, recall_score is 0.8271704180064309, f1-score is 0.8335358444714459\n","sklearn:confusion_matrix is \n","[[1060  196]\n"," [ 215 1029]]\n","TEST:in batch[26/26] accuracy is: 0.91, total accuracy is: 0.8384615384615385\n","\n","sklearn: now accuracy_score is 0.8384615384615385,  precision_score is 0.8457907159716759, recall_score is 0.827559661277906, f1-score is 0.8365758754863812\n","sklearn:confusion_matrix is \n","[[1105  196]\n"," [ 224 1075]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Z35ydyIZiKoz","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}